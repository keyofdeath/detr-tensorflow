{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"../img/auvisus.svg\" width=\"100\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEtection TRansformer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from detr_models.detr.model import DETR\n",
    "from detr_models.data_feeder.pvoc_feeder import PVOCFeeder\n",
    "from detr_models.data_feeder.coco_feeder import COCOFeeder\n",
    "from detr_models.data_feeder.uuid_iterator import UUIDIterator\n",
    "from detr_models.detr.config import DefaultDETRConfig\n",
    "\n",
    "from detr_models.backbone.backbone import Backbone\n",
    "from detr_models.transformer.transformer import Transformer\n",
    "from detr_models.detr.segmentation import SegmentationHead\n",
    "from detr_models.transformer.attention import MultiHeadAttentionMap\n",
    "\n",
    "from detr_models.detr.utils import create_positional_encodings, get_image_information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify storage path\n",
    "storage_path = input(prompt='Please specify the storage path:\\n')\n",
    "batch_size = 1\n",
    "\n",
    "# Additional Information used for initialization\n",
    "config = DefaultDETRConfig()\n",
    "training_config = {\n",
    "        \"storage_path\": storage_path,\n",
    "        \"batch_size\": batch_size,\n",
    "    }\n",
    "\n",
    "input_shape, count_images = get_image_information(storage_path, config.data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feeder = COCOFeeder(\n",
    "        storage_path=training_config[\"storage_path\"],\n",
    "        batch_size=training_config[\"batch_size\"],\n",
    "        num_queries=config.num_queries,\n",
    "        num_classes=config.num_classes,\n",
    "        image_width=config.image_width,\n",
    "        image_height=config.image_height,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = next(data_feeder(False))\n",
    "\n",
    "batch_images = input_data[0]\n",
    "batch_cls = input_data[1]\n",
    "batch_bboxs = input_data[2]\n",
    "obj_indices = input_data[3]\n",
    "batch_masks = input_data[4]\n",
    "\n",
    "print(\"Batch Images: {}\".format(batch_images.shape))\n",
    "print(\"Batch Target Class Labels: {}\".format(batch_cls.shape))\n",
    "print(\"Batch Target Bounding Boxes: {}\".format(batch_bboxs.shape))\n",
    "print(\"Batch Target Masks: {}\".format(batch_masks.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Backbones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backbone Input:**  \n",
    "$3 \\times H_0 \\times W_0$ ( $H_0,W_0$: Height and Width of Image)\n",
    "\n",
    "\n",
    "**Backbone Output:**  \n",
    "$C \\times H \\times W$ ( $H,W$: Height and Width of Feature Map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Backbone Configuration\n",
    "# Mame, Config for Keras and output flag for segmentation\n",
    "backbone_name = \"ResNet50\"\n",
    "backbone_config = {\n",
    "        \"input_shape\": input_shape,\n",
    "        \"include_top\": False,\n",
    "        \"weights\": \"imagenet\",\n",
    "    }\n",
    "return_intermediate = True\n",
    "\n",
    "backbone = Backbone(backbone_name, backbone_config, return_intermediate).model\n",
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Backbone Configuration\n",
    "# Mame, Config for Keras and output flag for segmentation\n",
    "backbone_name = \"MobileNetV2\"\n",
    "backbone_config = {\n",
    "        \"input_shape\": input_shape,\n",
    "        \"include_top\": False,\n",
    "        \"weights\": \"imagenet\",\n",
    "    }\n",
    "return_intermediate = False\n",
    "\n",
    "backbone = Backbone(backbone_name, backbone_config, return_intermediate).model\n",
    "backbone.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Backbone Outputs (return_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without intermediate feature maps\n",
    "backbone_name = \"ResNet50\"\n",
    "return_intermediate = False\n",
    "\n",
    "backbone = Backbone(backbone_name, backbone_config, return_intermediate).model\n",
    "\n",
    "feature_map = backbone(batch_images)\n",
    "print(\"Feature Map Shape: {}\".format(feature_map.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With intermediate feature maps\n",
    "backbone_name = \"ResNet50\"\n",
    "return_intermediate = True\n",
    "\n",
    "backbone = Backbone(backbone_name, backbone_config, return_intermediate).model\n",
    "\n",
    "feature_map = backbone(batch_images)\n",
    "for idx, output in enumerate(feature_map):\n",
    "    print(\"Level {} - Feature Map Shape: {}\".format(idx, output.shape))\n",
    "    \n",
    "fpn_maps = feature_map[:-1]\n",
    "feature_map = feature_map[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Positional Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_shape = feature_map.shape[1::]\n",
    "positional_encodings = create_positional_encodings(fm_shape, config.dim_transformer//2, batch_size=1)\n",
    "print(\"Positional Encodings Shape: {}\".format(positional_encodings.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Query Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pos = tf.ones((config.num_queries), dtype=tf.float32)\n",
    "query_pos = tf.repeat(\n",
    "    tf.expand_dims(query_pos, axis=0), repeats=batch_size, axis=0\n",
    ")\n",
    "query_embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=config.num_queries, output_dim=config.dim_transformer\n",
    ")(query_pos)\n",
    "\n",
    "print(\"Query Embeddings Shape: {}\".format(query_embedding.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prepare Input Data For Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backbone Output:**  \n",
    "$C \\times H \\times W$ ( $H,W$: Height and Width of Feature Map)\n",
    "\n",
    "\n",
    "**Transofmer Input:**\n",
    "1. Reduce to smaller channel size  \n",
    "$d \\times H \\times W$ ( $d$: Dimension of Transformer, $H,W$: Height and Width of Feature Map)    \n",
    "  \n",
    "  \n",
    "2. Collapse Height and Width (inside Transformer)\n",
    "$d \\times HW$ ( $d$: Dimension of Transformer, $H,W$: Height and Width of Feature Map)\n",
    "\n",
    "**Transofmer Output:**  \n",
    "$N \\times d$ ($N$: Number of Queries, $d$ Dimension of Transformer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_input = tf.keras.layers.Conv2D(config.dim_transformer, kernel_size=1)(\n",
    "            feature_map\n",
    "        )\n",
    "print(\"Transformer Input Shape: {}\".format(transformer_input.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "            config.num_transformer_layer,\n",
    "            config.dim_transformer,\n",
    "            config.num_heads,\n",
    "            config.dim_feedforward,\n",
    "        )\n",
    "\n",
    "transformer_output, memory = transformer([transformer_input, positional_encodings, query_embedding])\n",
    "\n",
    "print(\"Transformer Output Shape: {}\".format(transformer_output.shape) )\n",
    "print(\"Transformer Memory Shape: {}\".format(memory.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Classification and Bounding Box Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = tf.keras.layers.Dense(\n",
    "    units=config.num_classes + 1, activation=\"softmax\"\n",
    ")(transformer_output)\n",
    "\n",
    "bbox_pred = tf.keras.layers.Dense(units=4, activation=\"sigmoid\")(\n",
    "    transformer_output\n",
    ")\n",
    "\n",
    "print(\"Classification Output Shape: {}\".format(cls_pred.shape))\n",
    "print(\"Bounding Box Output Shape: {}\".format(bbox_pred.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Segmentation Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input:**\n",
    "1. Box Embeddings:  \n",
    "$d \\times N$  ($d$: Dimension of Transformer, $N$: Number of queries)\n",
    "\n",
    "\n",
    "\n",
    "2. Encoded Image:  \n",
    "$d \\times H \\times W$ ($d$: Dimension of Transformer, $H,W$: Height and Width of Feature Map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. Attention Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map = MultiHeadAttentionMap(\n",
    "    dim_transformer=config.dim_transformer,\n",
    "    num_heads=config.num_heads,\n",
    "    dropout=0.0\n",
    ")\n",
    "\n",
    "attention_hmaps = attention_map([memory,transformer_output])\n",
    "print(\"BBOX Mask Shape: {}\".format(attention_hmaps.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_map.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Segmentation Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_head = SegmentationHead(\n",
    "    num_heads=config.num_heads,\n",
    "    dim_transformer=config.dim_transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Segmentation Head Input:\")\n",
    "print(\"Transformer Input: {}\".format(transformer_input.shape))\n",
    "print(\"Bounding Box Mask: {}\".format(attention_hmaps.shape))\n",
    "\n",
    "mask_pred = segmentation_head([transformer_input, attention_hmaps, fpn_maps])\n",
    "\n",
    "\n",
    "print(\"Segmentation Head Output Shape: {}\".format(mask_pred.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_head.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Complete DETR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1. Without Segmentation Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr = DETR(\n",
    "        input_shape=input_shape,\n",
    "        num_queries=config.num_queries,\n",
    "        num_classes=config.num_classes,\n",
    "        num_heads=config.num_heads,\n",
    "        dim_transformer=config.dim_transformer,\n",
    "        dim_feedforward=config.dim_feedforward,\n",
    "        num_transformer_layer=config.num_transformer_layer,\n",
    "        backbone_name=config.backbone_name,\n",
    "        backbone_config=backbone_config,\n",
    "        train_backbone=config.train_backbone,\n",
    "    )\n",
    "\n",
    "detr.build_model()\n",
    "\n",
    "detr.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Including Segmentation Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr = DETR(\n",
    "        input_shape=input_shape,\n",
    "        num_queries=config.num_queries,\n",
    "        num_classes=config.num_classes,\n",
    "        num_heads=config.num_heads,\n",
    "        dim_transformer=config.dim_transformer,\n",
    "        dim_feedforward=config.dim_feedforward,\n",
    "        num_transformer_layer=config.num_transformer_layer,\n",
    "        backbone_name=config.backbone_name,\n",
    "        backbone_config=backbone_config,\n",
    "        train_backbone=config.train_backbone,\n",
    "    )\n",
    "\n",
    "detr.build_model(False, True)\n",
    "\n",
    "detr.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This Notebook was created by: [auvisus GmbH](https://www.auvisus.com/)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_venv",
   "language": "python",
   "name": "python3_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
